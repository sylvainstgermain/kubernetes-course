


kubectl create -f https://static.alta3.com/projects/k8s/k8s-countdown.yaml

watch kubectl get jobs
NAME                      COMPLETIONS  DURATION  AGE
countdown                 1/1          12s       5s

When the job initially runs, it spawns a pod name, then runs under that name,
 and then it dies. Sad but true! However it leaves its logs behind which you 
 can collect and examine. 
First you need to find the dead job's pod name as follows:

# 
PODS=$(kubectl get pods --selector=job-name=countdown --output=jsonpath={.items..metadata.name})

#Using the $PODS variable, print the logs to see the standard output.
kubectl logs $PODS

#Let's examine how that slick command (two steps back) worked. We'll dig a little
# deeper by selecting the first 10 lines of the jobs YAML
kubectl get pods --selector=job-name=countdown --output=yaml | grep -A10 ^apiVersion:

#Delete the job.
kubectl delete job countdown

kubectl apply -f objets-cours/countdown.yaml

#Now, watch the jobs automatically start every minute
kubectl get pods -w

NAME                         READY   STATUS    RESTARTS   AGE
countdown-1614791880-7jpkg   0/1     Pending   0          0s
countdown-1614791880-7jpkg   0/1     Pending   0          0s
countdown-1614791880-7jpkg   0/1     ContainerCreating   0          0s
countdown-1614791880-7jpkg   0/1     Completed           0          3s

# check jobs
kubectl get cj
kubectl get cj -w

#
kubectl logs countdown-1614791880-7jpkg

#Delete your cron job, or it will run continuously.
kubectl delete cj countdown
kubectl delete pods --all

# verifu delete
kubectl get cj
No resources found in default namespace.

kubectl get pods
No resources found in default namespace.

























