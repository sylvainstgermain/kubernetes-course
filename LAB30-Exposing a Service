------------------------------------------------------
kubectl apply -f objets-cours/...
kubectl config current-context
kubectl delete all --all

#Confirm namespace test exists.
kubectl get namespaces
---------------------------------------------------
These are the three primary types of Services that you need to be familiar with:

ClusterIP Service
NodePort Service
LoadBalancer Service
1 - ClusterIP Service
A ClusterIP service can only be accessed from inside of the cluster. This means that you, as a Kubernetes Administrator, have the ability to access all of the ClusterIP services via kubectl.

This is accessible via the spec.clusterIp port. If a spec.ports[*].targetPort is set it will route from the port to the targetPort. The CLUSTER-IP you get when calling kubectl get services is the IP assigned to this service within the cluster internally.

2 - NodePort Service
A NodePort Service simply exposes a specific port on every node in your cluster, and any traffic that hits that port will then be directed into an EndPoint (Pod) via iptables or netfilter rules.

Your NodeIPs are the external IP addresses of the nodes. If you access this service on a nodePort from the node's external IP, it will route the request to spec.clusterIp:spec.ports[].port, which will in turn route it to your spec.ports[].targetPort, if set.

Here are two diagrams to help you see what may happen. If it is not clear to you how a nodePort works, please ask your instructor.

Please Note: These "Single endpoints" represent Pods residing inside of the Node that is pointing to it

Access via node-2 Client to endpoint flow.

￼
                   +---------+
                   | client  |
                   +--+---^--+
                     1|   |6
+---------+   2    +--v---+--+
|         |  <---  |         |
|  node 1 |  SNAT  |  node 2 |
|         |  --->  |         |
+---+-^---+   5    +---------+
  3 | | 4
+---v-+---+
| Single  |
|endpoint |
+---------+
Access via node1 Client to endpoint flow

￼
                        +---------+
                        | client  |
                  1     +---^--^--+
         +------------------+  |
No SNAT  |  +-------------------
         |  |      4
     +---+--+--+        +---------+
     |  node 1 |        |  node 2 |
     +---+-^---+        +---------+
       2 | | 3
     +---v-+---+
     | Single  |
     |endpoint |
     +---------+
3 - LoadBalancer Service
Most likely, you do not want to be exposing n number of Node IP addresses as Public IP addresses. Most cloud providers, such as GKE and AWS, have built Load Balancers into their cloud that a Kubernetes loadBalancer service is able to dynamically configure.

A loadBalancer service will assure Pods are ready, and then notify the Cloud Load Balancer of the route to the specific Pods. You can access this service from your load balancer's IP address, which routes your request to a nodePort, which in turn routes the request to the clusterIP (this then load balances to the pods providing that service). You can access this service as you would a NodePort or a ClusterIP service as well.

Envoy (written by Lyft) is typically the load balancer of choice. Unfortunately, Kubernetes has poor support for other External Load Balancers (or maybe other external load balancers have poor support for Kubernetes), so unless you're using Envoy, it is likely you will need to create your own "glue code" to connect the loadBalancer service to your own Load Balancer.

If you are interested in learning more about Services, check out these other resources:

Exposing Exteranl IP addresses - https://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/
Basics of Exposing Services - https://kubernetes.io/docs/tutorials/kubernetes-basics/expose/expose-intro/
Understanding Services - https://kubernetes.io/docs/tasks/access-application-cluster/service-access-application-cluster/

You made this file in a previous lab, but let's make sure you didn't make any errors in creating it. Run the following command to download the file nginx.conf.
wget https://static.alta3.com/projects/k8s/nginx.conf.final -O ./nginx.conf

n a previous lab, we created an nginx.conf config map, but it has changed since then. So, delete the old map.
kubectl delete configmap nginx-conf

#Now, recreate an updated nginx-conf configmap
kubectl create configmap nginx-conf --from-file=objets-cours/nginx.conf

What is a configMap? We want this new configuration file to be 'injected'
 into our pod at the time it is created. This behavior takes the place 
 of creating a new image with the proper configuration file in place, as 
 well as manually copying the new file into the pod. First create a 
 ConfigMap that includes your configuration data, then describe the config 
 map within the manifest.

 wget https://static.alta3.com/projects/k8s/index.html2 -O ./index.html
kubectl create configmap index-file --from-file=objets-cours/index.html 

#Verify all 3 ConfigMaps are loaded.
kubectl get cm

#Check to see what pods are currently running.
kubectl get pods

#Clean up your environment by deleting the running pods.

#Create the pod.
---
apiVersion: v1   # https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#_v1_podspec
kind: Pod                      # MUST - create a Pod resource
metadata:                      # MUST - metadata.name provides the 'name' for the resource
  name: nginx-configured       # MUST - name of the resource
  labels:                      # OPTIONAL (best practice) - allows manipulation of resource by label
    app: nginx-configured      # OPTIONAL - example of a key: value key pair
spec:                          # MUST - what you want to build
  containers:                  # MUST - describe 1 or more containers within the pod
  - name: nginx                # MUST - name of the container within the pod
    image: nginx:1.18.0         # MUST - image nginx and version 1.18.0 from hub.docker.com
    ports:                     # exposes ports on the pod
    - name: chris              # name of mapped port (could also be Tim, or pinecone)
      containerPort: 80        # exposed port
    volumeMounts:                     # describes where your volumes will be availabe within the container
    - name: nginx-proxy-config        # matches spec.volumes[0].name
      mountPath: /etc/nginx/nginx.conf  # this is WHERE it will appear inside of the container
      subPath: nginx.conf             # required to overwrite a file that is already within the container
    - name: my-index-file             # matches spec.volumes[1].name
      mountPath: /var/www/index.html
      subPath: index.html
    - name: static-demo-data          # matches spec.volumes[2].name
      mountPath: /var/www/static/nginx.txt
      subPath: nginx.txt
  volumes:  
  - name: nginx-proxy-config      # matches spec.volumeMounts[0].name
    configMap:
      name: nginx-conf            # name of a configMap
  - name: my-index-file           # matches spec.volumeMounts[1].name
    configMap:
      name: index-file            # name of a configMap
  - name: static-demo-data        # matches spec.volumeMounts[2].name
    configMap:
      name: nginx-txt             # name of a configMap

kubectl apply -f objets-cours/nginx-configured.yaml

# Confirm which services are currently running. YOU MAY NOT HAVE ANY/ALL 
OF THESE SERVICES.

kubectl get services
NAME            TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
kubernetes      ClusterIP   172.16.3.1     <none>        443/TCP   179m
simpleservice   ClusterIP   172.16.3.158   <none>        80/TCP    176m

#Expose the pod.
kubectl expose pod/nginx-configured --type="NodePort" --port 80

#Confirm that the new service has been added to the list of services.
kubectl get services | grep nginx
nginx-configured   NodePort    172.16.3.209   <none>        80:31263/TCP   19s

#Run the describe services command to see what the output looks like.
kubectl describe services/nginx-configured
Name:                     nginx-configured
Namespace:                default
Labels:                   app=nginx-configured
Annotations:              <none>
Selector:                 app=nginx-configured
Type:                     NodePort
IP:                       172.16.3.209
Port:                     <unset>  80/TCP
TargetPort:               80/TCP
NodePort:                 <unset>  31263/TCP
Endpoints:                192.168.247.41:80
Session Affinity:         None
External Traffic Policy:  Cluster
Events:                   <none>

#Get your test pod's node port and store it in an environmental variable called NODE_PORT
export NODE_PORT=$(kubectl get services/nginx-configured -o go-template='{{(index .spec.ports 0).nodePort}}')

#ervices/nginx-configured -o go-template='{{(index .spec.ports 0).nodePort}}'
kubectl describe pod nginx-configured | grep "Node:\|IP:"
ode:         node-2/10.9.54.194
IP:           192.168.247.41
  IP:  192.168.247.41

echo Your NODE_PORT = $NODE_PORT
Your NODE_PORT = 31263
#he following command will curl node-1 on your service's nodeport.
curl node-1:$NODE_PORT/static/nginx.txt

Answer the following questions:

Question: What node is your pod actually running on?
Answer: kubectl get pods -o wide or kubectl describe pods can help you find those.
Question: If you curl the service's NodePort on the nodes that are not hosting the pod, will you STILL get a response?
Answer: Yes- the last few lab directions show you what happens.
Question: What is the IP of each node? (node-1, node-2, node-3)?
Answer: kubectl describe nodes | grep IP should do the trick!
Question: If you ping node-1, node-2, and node-3 does it resolve to the expected IP address?
Answer: It should resolve correctly.
Question: What TCP socket would you curl to test if you can access your service at node-1?
Answer: The one that is listed as the NodePort.
Question: What TCP socket would you curl to test if you can access your service at node-2?
Answer: Same as answer 5.
Question: What TCP socket would you curl to test if you can access your service at node-3?
Answer: Same as answer 5.
Do NOT proceed without answering all of the questions above.

The following command will curl node-1 on your service's nodeport.

student@bchd:~$ curl node-1:$NODE_PORT/static/nginx.txt￼

If the above command fails, see if your pod is running with "kubect get pods". If the pod is failing to come up, delete it with "kubectl delete -f nginx-configured.yaml". Next, check to ensure your configMaps are in place with "kubect get cm". If you do not have all 3 config maps, or if they were made in correctly, your Pod will fail to boot. To fix, try deleting all of your configmaps, recreating them, and then recreating your pod.

The following command will curl node-2 on your service's nodeport.

student@bchd:~$ curl node-2:$NODE_PORT/static/nginx.txt￼

The following command will curl node-3 on your service's nodeport.

student@bchd:~$ curl node-3:$NODE_PORT/static/nginx.txt￼

